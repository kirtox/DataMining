{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"backup_Copy Spark Milb Tutorial 2019: PM25 Prediction.ipynb","provenance":[{"file_id":"1A1B42qm4_YpnUEGThH_0X__sUYMSvgcr","timestamp":1577344553323},{"file_id":"1nJQKp1ZGv1yJF6_Ov4QNTA76a_sfQNQa","timestamp":1576650253656}],"collapsed_sections":["TftpsPXb6qlh","NH4f0EaZyMzn"]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"smAgUJKT6lvw","colab_type":"text"},"source":["# 環境設定"]},{"cell_type":"code","metadata":{"id":"5HSCKUurUcLK","colab_type":"code","outputId":"be1053cc-f7c1-4625-b35f-80842c870d1a","executionInfo":{"status":"ok","timestamp":1577429978630,"user_tz":-480,"elapsed":38881,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AOobZdBlRusw","colab_type":"code","outputId":"dbf1b031-3336-4875-f45e-712205790f3a","executionInfo":{"status":"ok","timestamp":1577430020525,"user_tz":-480,"elapsed":13162,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 環境初始化 (大約三至五分鐘)\n","! wget -O init_env.sh https://www.dropbox.com/s/6bnwn8u2hz19s59/init_env.sh && \\\n","bash init_env.sh"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-12-27 07:01:57--  https://www.dropbox.com/s/6bnwn8u2hz19s59/init_env.sh\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/6bnwn8u2hz19s59/init_env.sh [following]\n","--2019-12-27 07:01:58--  https://www.dropbox.com/s/raw/6bnwn8u2hz19s59/init_env.sh\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uca1d4abe1245d15aaba97236cfc.dl.dropboxusercontent.com/cd/0/inline/AvADF9n2ckgNTL8loNhs30ULI4xAbVTf4jX8oVANqDSh__DhEnWpnWE5nTlI4fXLW3JRcjsFyrQhV_uAZyrHaEbpRPs_aSmBcDnaWaNVY0TUdw/file# [following]\n","--2019-12-27 07:01:58--  https://uca1d4abe1245d15aaba97236cfc.dl.dropboxusercontent.com/cd/0/inline/AvADF9n2ckgNTL8loNhs30ULI4xAbVTf4jX8oVANqDSh__DhEnWpnWE5nTlI4fXLW3JRcjsFyrQhV_uAZyrHaEbpRPs_aSmBcDnaWaNVY0TUdw/file\n","Resolving uca1d4abe1245d15aaba97236cfc.dl.dropboxusercontent.com (uca1d4abe1245d15aaba97236cfc.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:601b:6::a27d:806\n","Connecting to uca1d4abe1245d15aaba97236cfc.dl.dropboxusercontent.com (uca1d4abe1245d15aaba97236cfc.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 336 [text/plain]\n","Saving to: ‘init_env.sh’\n","\n","init_env.sh         100%[===================>]     336  --.-KB/s    in 0s      \n","\n","2019-12-27 07:01:58 (26.3 MB/s) - ‘init_env.sh’ saved [336/336]\n","\n","--2019-12-27 07:01:58--  https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz\n","Resolving d3kbcqa49mib13.cloudfront.net (d3kbcqa49mib13.cloudfront.net)... 13.249.94.105, 13.249.94.63, 13.249.94.94, ...\n","Connecting to d3kbcqa49mib13.cloudfront.net (d3kbcqa49mib13.cloudfront.net)|13.249.94.105|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 203728858 (194M) [application/x-tar]\n","Saving to: ‘spark-2.2.0-bin-hadoop2.7.tgz’\n","\n","spark-2.2.0-bin-had 100%[===================>] 194.29M  37.4MB/s    in 5.5s    \n","\n","2019-12-27 07:02:04 (35.3 MB/s) - ‘spark-2.2.0-bin-hadoop2.7.tgz’ saved [203728858/203728858]\n","\n","spark-2.2.0-bin-hadoop2.7/\n","spark-2.2.0-bin-hadoop2.7/NOTICE\n","spark-2.2.0-bin-hadoop2.7/jars/\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-common-1.8.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-net-2.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/antlr-runtime-3.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-hadoop-1.8.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-sketch_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/stream-2.7.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/kryo-shaded-3.0.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/metrics-jvm-3.1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/RoaringBitmap-0.5.11.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jta-1.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jets3t-0.9.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-compress-1.4.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-beanutils-1.7.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-format-2.3.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/avro-1.7.7.jar\n","spark-2.2.0-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jline-2.12.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/metrics-core-3.1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/java-xmlbuilder-1.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n","spark-2.2.0-bin-hadoop2.7/jars/xbean-asm5-shaded-4.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n","spark-2.2.0-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javax.inject-1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-sql_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/json4s-jackson_2.11-3.2.11.jar\n","spark-2.2.0-bin-hadoop2.7/jars/json4s-ast_2.11-3.2.11.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-codec-1.10.jar\n","spark-2.2.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-common-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-graphx_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n","spark-2.2.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n","spark-2.2.0-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-network-common_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/pmml-schema-1.2.15.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/joda-time-2.9.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/curator-recipes-2.6.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-server-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n","spark-2.2.0-bin-hadoop2.7/jars/httpclient-4.5.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/snappy-0.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n","spark-2.2.0-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-tags_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-databind-2.6.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/curator-client-2.6.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/paranamer-2.6.jar\n","spark-2.2.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/json4s-core_2.11-3.2.11.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jsr305-1.3.9.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-repl_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n","spark-2.2.0-bin-hadoop2.7/jars/pyrolite-4.13.jar\n","spark-2.2.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar\n","spark-2.2.0-bin-hadoop2.7/jars/scala-xml_2.11-1.0.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar\n","spark-2.2.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jtransforms-2.4.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n","spark-2.2.0-bin-hadoop2.7/jars/guice-3.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/httpcore-4.4.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-yarn_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-hive_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n","spark-2.2.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/netty-all-4.0.43.Final.jar\n","spark-2.2.0-bin-hadoop2.7/jars/curator-framework-2.6.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/avro-ipc-1.7.7.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/mesos-1.0.0-shaded-protobuf.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-annotations-2.6.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-jackson-1.8.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.6.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/janino-3.0.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/antlr4-runtime-4.5.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jpam-1.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-lang3-3.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar\n","spark-2.2.0-bin-hadoop2.7/jars/bcprov-jdk15on-1.51.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-launcher_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/metrics-graphite-3.1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n","spark-2.2.0-bin-hadoop2.7/jars/lz4-1.3.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/core-1.1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-mesos_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/antlr-2.7.7.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/mx4j-3.0.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-beanutils-core-1.8.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/libthrift-0.9.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-encoding-1.8.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-mllib_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n","spark-2.2.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n","spark-2.2.0-bin-hadoop2.7/jars/mail-1.4.7.jar\n","spark-2.2.0-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/metrics-json-3.1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/scalap-2.11.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/zookeeper-3.4.6.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/ivy-2.4.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/py4j-0.10.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n","spark-2.2.0-bin-hadoop2.7/jars/pmml-model-1.2.15.jar\n","spark-2.2.0-bin-hadoop2.7/jars/parquet-column-1.8.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar\n","spark-2.2.0-bin-hadoop2.7/jars/breeze_2.11-0.13.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/chill-java-0.8.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/avro-mapred-1.7.7-hadoop2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/snappy-java-1.1.2.6.jar\n","spark-2.2.0-bin-hadoop2.7/jars/base64-2.3.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-compiler-3.0.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n","spark-2.2.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/objenesis-2.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jersey-client-2.22.2.jar\n","spark-2.2.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/univocity-parsers-2.2.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.0.4.jar\n","spark-2.2.0-bin-hadoop2.7/jars/jackson-core-2.6.5.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/xz-1.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/scala-reflect-2.11.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n","spark-2.2.0-bin-hadoop2.7/jars/scala-compiler-2.11.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar\n","spark-2.2.0-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-core_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n","spark-2.2.0-bin-hadoop2.7/jars/netty-3.9.9.Final.jar\n","spark-2.2.0-bin-hadoop2.7/jars/spark-streaming_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/chill_2.11-0.8.0.jar\n","spark-2.2.0-bin-hadoop2.7/jars/scala-library-2.11.8.jar\n","spark-2.2.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar\n","spark-2.2.0-bin-hadoop2.7/python/\n","spark-2.2.0-bin-hadoop2.7/python/run-tests.py\n","spark-2.2.0-bin-hadoop2.7/python/test_support/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/hello/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n","spark-2.2.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n","spark-2.2.0-bin-hadoop2.7/python/test_support/userlibrary.py\n","spark-2.2.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/people.json\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/people1.json\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/streaming/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n","spark-2.2.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n","spark-2.2.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n","spark-2.2.0-bin-hadoop2.7/python/pylintrc\n","spark-2.2.0-bin-hadoop2.7/python/docs/\n","spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.ml.rst\n","spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n","spark-2.2.0-bin-hadoop2.7/python/docs/conf.py\n","spark-2.2.0-bin-hadoop2.7/python/docs/_templates/\n","spark-2.2.0-bin-hadoop2.7/python/docs/_templates/layout.html\n","spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.rst\n","spark-2.2.0-bin-hadoop2.7/python/docs/make.bat\n","spark-2.2.0-bin-hadoop2.7/python/docs/epytext.py\n","spark-2.2.0-bin-hadoop2.7/python/docs/make2.bat\n","spark-2.2.0-bin-hadoop2.7/python/docs/index.rst\n","spark-2.2.0-bin-hadoop2.7/python/docs/_static/\n","spark-2.2.0-bin-hadoop2.7/python/docs/_static/pyspark.js\n","spark-2.2.0-bin-hadoop2.7/python/docs/_static/pyspark.css\n","spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.sql.rst\n","spark-2.2.0-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n","spark-2.2.0-bin-hadoop2.7/python/docs/Makefile\n","spark-2.2.0-bin-hadoop2.7/python/.gitignore\n","spark-2.2.0-bin-hadoop2.7/python/MANIFEST.in\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/status.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/version.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/conf.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/base.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/util.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/tests.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/common.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/statcounter.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/profiler.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/serializers.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/shell.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/session.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/window.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/tests.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/group.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/types.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/context.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/column.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/util.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/python/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/python/pyspark/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/daemon.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/tests.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/heapq3.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/broadcast.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/shuffle.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/cloudpickle.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/accumulators.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/tests.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/flume.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/kafka.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/context.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/join.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/tests.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/rdd.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/worker.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/files.py\n","spark-2.2.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n","spark-2.2.0-bin-hadoop2.7/python/setup.cfg\n","spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/\n","spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n","spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n","spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n","spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n","spark-2.2.0-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n","spark-2.2.0-bin-hadoop2.7/python/run-tests\n","spark-2.2.0-bin-hadoop2.7/python/dist/\n","spark-2.2.0-bin-hadoop2.7/python/setup.py\n","spark-2.2.0-bin-hadoop2.7/python/lib/\n","spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip\n","spark-2.2.0-bin-hadoop2.7/python/lib/pyspark.zip\n","spark-2.2.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n","spark-2.2.0-bin-hadoop2.7/python/README.md\n","spark-2.2.0-bin-hadoop2.7/RELEASE\n","spark-2.2.0-bin-hadoop2.7/sbin/\n","spark-2.2.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/spark-daemon.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-slaves.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-shuffle-service.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-history-server.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/spark-config.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-history-server.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-shuffle-service.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/spark-daemons.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-all.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-master.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-slave.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-slave.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-slaves.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/stop-all.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/slaves.sh\n","spark-2.2.0-bin-hadoop2.7/sbin/start-master.sh\n","spark-2.2.0-bin-hadoop2.7/examples/\n","spark-2.2.0-bin-hadoop2.7/examples/src/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/pi.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/kafka_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/direct_kafka_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/streaming/flume_wordcount.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/als.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/python/sort.py\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaFlumeEventCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaKafkaWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/FlumePollingEventCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/FlumeEventCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/KafkaWordCount.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/people.json\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n","spark-2.2.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n","spark-2.2.0-bin-hadoop2.7/examples/jars/\n","spark-2.2.0-bin-hadoop2.7/examples/jars/scopt_2.11-3.3.0.jar\n","spark-2.2.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.2.0.jar\n","spark-2.2.0-bin-hadoop2.7/data/\n","spark-2.2.0-bin-hadoop2.7/data/graphx/\n","spark-2.2.0-bin-hadoop2.7/data/graphx/followers.txt\n","spark-2.2.0-bin-hadoop2.7/data/graphx/users.txt\n","spark-2.2.0-bin-hadoop2.7/data/streaming/\n","spark-2.2.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/\n","spark-2.2.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/pic_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/als/\n","spark-2.2.0-bin-hadoop2.7/data/mllib/als/test.data\n","spark-2.2.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/ridge-data/\n","spark-2.2.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n","spark-2.2.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n","spark-2.2.0-bin-hadoop2.7/R/\n","spark-2.2.0-bin-hadoop2.7/R/lib/\n","spark-2.2.0-bin-hadoop2.7/R/lib/sparkr.zip\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/groupBy.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/covar_pop.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sampleBy.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sql.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/year.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tan.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GBTRegressionModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/last_day.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sign.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hint.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/randn.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/orderBy.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/otherwise.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/AFTSurvivalRegressionModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hashCode.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/bin.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dim.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.svmLinear.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/minute.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createExternalTable-deprecated.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/distinct.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.conf.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/print.jobj.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/md5.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cbrt.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.ml.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dapplyCollect.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/acos.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tables.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/NaiveBayesModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sum.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/structType.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hex.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/isLocal.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.jdbc.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/from_utc_timestamp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tableNames.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createDataFrame.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/isStreaming.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/toJSON.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.getSparkFiles.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/except.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/LDAModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/months_between.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark_partition_id.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.parquet.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sumDistinct.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/awaitTermination.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/BisectingKMeansModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sha2.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/abs.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/date_format.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/withColumn.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dayofyear.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sort_array.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/storageLevel.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setCurrentDatabase.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ceil.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/floor.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/stddev_pop.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sd.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/print.structType.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.survreg.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/predict.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/count.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unhex.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/mean.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/instr.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/from_unixtime.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/saveAsTable.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ltrim.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkRHive.init-deprecated.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.parquet.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/match.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/is.nan.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.ml.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lag.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.json.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unpersist.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/corr.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.callJStatic.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rint.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/LinearSVCModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.gbt.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/RandomForestClassificationModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/persist.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/var_pop.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/selectExpr.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/crc32.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/expr.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.callJMethod.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/with.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/generateAliasesForIntersectedCols.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GeneralizedLinearRegressionModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/IsotonicRegressionModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setLogLevel.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/shiftRightUnsigned.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/base64.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/array_contains.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/expm1.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.orc.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.version.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/insertInto.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/SparkDataFrame.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/merge.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dayofmonth.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listDatabases.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/summarize.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/format_number.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/from_json.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dropDuplicates.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cache.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.text.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/approxCountDistinct.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkRSQL.init-deprecated.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/LogisticRegressionModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/stddev_samp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/pivot.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/showDF.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/between.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/struct.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/subset.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/posexplode.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lit.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/shiftLeft.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/glm.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hypot.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/recoverPartitions.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.session.stop.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/translate.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/drop.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GBTClassificationModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/shiftRight.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/regexp_replace.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/randomSplit.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/length.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rowsBetween.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.jdbc.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/schema.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/toRadians.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/filter.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/bround.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createOrReplaceTempView.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cancelJobGroup.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/second.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/upper.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/head.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/limit.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/concat_ws.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/when.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/FPGrowthModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/install.spark.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.newJObject.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dropTempView.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unbase64.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/soundex.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/structField.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.addFile.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.bisectingKmeans.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cacheTable.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cosh.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.mlp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ntile.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/atan2.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.kstest.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dtypes.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/reverse.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sinh.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.lda.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/createTable.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/negate.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/asin.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hash.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rank.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/toDegrees.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/columns.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/columnfunctions.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/substring_index.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_timestamp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.naiveBayes.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/atan.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.isoreg.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/factorial.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/countDistinct.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/quarter.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setCheckpointDir.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/least.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.text.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/windowOrderBy.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dapply.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/coalesce.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/refreshByPath.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cume_dist.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dense_rank.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/freqItems.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/getNumPartitions.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/KMeansModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.session.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/arrange.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.stream.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/encode.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.glm.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/isActive.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/crossJoin.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rpad.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/uncacheTable.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/size.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/conv.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log10.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/collect.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.stream.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/format_string.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/windowPartitionBy.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/union.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/stopQuery.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/dropTempTable-deprecated.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/endsWith.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/startsWith.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/nanvl.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/mutate.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/explain.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cov.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/var_samp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log2.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/registerTempTable-deprecated.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lastProgress.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/attach.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/min.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ncol.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/month.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/window.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/partitionBy.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/percent_rank.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listFunctions.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_utc_timestamp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/crosstab.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/take.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/exp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_json.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/column.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ifelse.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GaussianMixtureModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.logit.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/show.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/setJobGroup.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/KSTest-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/clearJobGroup.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/last.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/printSchema.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rename.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rbind.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/over.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/MultilayerPerceptronClassificationModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/coltypes.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/datediff.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lead.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/summary.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/WindowSpec.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/unix_timestamp.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tanh.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listColumns.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/to_date.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.uiWebUrl.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/max.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/var.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/print.structField.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.als.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/alias.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sha1.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/status.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.orc.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/currentDatabase.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/write.df.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/round.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sparkR.init-deprecated.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/refreshTable.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/nrow.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/pmod.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/intersect.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rtrim.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/substr.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/levenshtein.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/monotonically_increasing_id.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/checkpoint.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/decode.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.lapply.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.json.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/RandomForestRegressionModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/trim.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/select.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/regexp_extract.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/as.data.frame.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rangeBetween.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/queryName.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sample.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lower.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/repartition.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/concat.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cast.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/date_add.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.fpGrowth.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/hour.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/initcap.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/explode.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/add_months.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/bitwiseNOT.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/approxQuantile.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/kurtosis.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/greatest.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/first.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/read.df.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/rand.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/next_day.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/clearCache.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/nafunctions.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/row_number.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/lpad.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/skewness.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/gapplyCollect.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/locate.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/avg.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sqrt.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/cos.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/log1p.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/str.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/StreamingQuery.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ALSModel-class.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/ascii.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/listTables.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/sin.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/histogram.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/weekofyear.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/GroupedData.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/fitted.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/date_sub.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/tableToDF.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.getSparkFilesRootDirectory.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/join.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/gapply.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.randomForest.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.kmeans.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/html/spark.gaussianMixture.html\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/profile/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/worker/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/tests/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n","spark-2.2.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n","spark-2.2.0-bin-hadoop2.7/licenses/\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-scalacheck.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-Mockito.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-junit-interface.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-boto.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-SnapTree.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jpmml-model.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jbcrypt.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-postgresql.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-DPark.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n","spark-2.2.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n","spark-2.2.0-bin-hadoop2.7/conf/\n","spark-2.2.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n","spark-2.2.0-bin-hadoop2.7/conf/metrics.properties.template\n","spark-2.2.0-bin-hadoop2.7/conf/spark-env.sh.template\n","spark-2.2.0-bin-hadoop2.7/conf/log4j.properties.template\n","spark-2.2.0-bin-hadoop2.7/conf/docker.properties.template\n","spark-2.2.0-bin-hadoop2.7/conf/slaves.template\n","spark-2.2.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n","spark-2.2.0-bin-hadoop2.7/LICENSE\n","spark-2.2.0-bin-hadoop2.7/bin/\n","spark-2.2.0-bin-hadoop2.7/bin/spark-shell\n","spark-2.2.0-bin-hadoop2.7/bin/spark-submit.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/spark-shell2.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/pyspark\n","spark-2.2.0-bin-hadoop2.7/bin/sparkR.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/spark-class2.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/run-example.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/spark-submit2.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/spark-class\n","spark-2.2.0-bin-hadoop2.7/bin/spark-submit\n","spark-2.2.0-bin-hadoop2.7/bin/spark-sql\n","spark-2.2.0-bin-hadoop2.7/bin/find-spark-home\n","spark-2.2.0-bin-hadoop2.7/bin/run-example\n","spark-2.2.0-bin-hadoop2.7/bin/beeline\n","spark-2.2.0-bin-hadoop2.7/bin/pyspark2.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/spark-shell.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/spark-class.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/pyspark.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/sparkR\n","spark-2.2.0-bin-hadoop2.7/bin/beeline.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/sparkR2.cmd\n","spark-2.2.0-bin-hadoop2.7/bin/load-spark-env.sh\n","spark-2.2.0-bin-hadoop2.7/bin/load-spark-env.cmd\n","spark-2.2.0-bin-hadoop2.7/yarn/\n","spark-2.2.0-bin-hadoop2.7/yarn/spark-2.2.0-yarn-shuffle.jar\n","spark-2.2.0-bin-hadoop2.7/README.md\n","環境初始化完畢\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xG7nN2zyUYYp","colab_type":"code","colab":{}},"source":["import os, sys\n","os.environ['SPARK_HOME'] = \"/usr/local/spark\"\n","os.environ['PYSPARK_PYTHON'] = \"/usr/local/bin/python\"\n","sys.path.append(\"/usr/local/spark/python/\")\n","sys.path.append(\"/usr/local/spark/python/lib/pyspark.zip\")\n","sys.path.append(\"/usr/local/spark/python/lib/py4j-0.10.4-src.zip\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUfG3ds3UacR","colab_type":"code","colab":{}},"source":["from pyspark import SparkContext\n","from pyspark import SparkConf\n","\n","sc = SparkContext()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EIye8lF5Gp5x","colab_type":"text"},"source":["# --------預處理部分--------\n"]},{"cell_type":"markdown","metadata":{"id":"TftpsPXb6qlh","colab_type":"text"},"source":["# 讀取資料"]},{"cell_type":"code","metadata":{"id":"7b29Tbg-Ueh3","colab_type":"code","outputId":"d6cb7d2d-e4a0-46ef-bf8d-983b1c0a3345","executionInfo":{"status":"ok","timestamp":1577430028691,"user_tz":-480,"elapsed":21177,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"source":["!wget -O pm25.csv \"https://www.dropbox.com/s/zkn3ba7pitv83el/pm2.5Taiwan.csv?dl=0\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-12-27 07:02:14--  https://www.dropbox.com/s/zkn3ba7pitv83el/pm2.5Taiwan.csv?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/zkn3ba7pitv83el/pm2.5Taiwan.csv [following]\n","--2019-12-27 07:02:14--  https://www.dropbox.com/s/raw/zkn3ba7pitv83el/pm2.5Taiwan.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucff8f15191d9e5942a8d69ad3a0.dl.dropboxusercontent.com/cd/0/inline/AvDkU5LiYvFPZyE1cDYnV4TPw2cL2AhXtJPhBX1uOANJypwv6_XWdpKulF-Z2jmQqnkkhSGhm-lEV-3WkFVbvoMYytVxG9_jWTLz-AbZSP2LWQ/file# [following]\n","--2019-12-27 07:02:14--  https://ucff8f15191d9e5942a8d69ad3a0.dl.dropboxusercontent.com/cd/0/inline/AvDkU5LiYvFPZyE1cDYnV4TPw2cL2AhXtJPhBX1uOANJypwv6_XWdpKulF-Z2jmQqnkkhSGhm-lEV-3WkFVbvoMYytVxG9_jWTLz-AbZSP2LWQ/file\n","Resolving ucff8f15191d9e5942a8d69ad3a0.dl.dropboxusercontent.com (ucff8f15191d9e5942a8d69ad3a0.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:601b:6::a27d:806\n","Connecting to ucff8f15191d9e5942a8d69ad3a0.dl.dropboxusercontent.com (ucff8f15191d9e5942a8d69ad3a0.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 50453822 (48M) [text/plain]\n","Saving to: ‘pm25.csv’\n","\n","pm25.csv            100%[===================>]  48.12M  79.7MB/s    in 0.6s    \n","\n","2019-12-27 07:02:15 (79.7 MB/s) - ‘pm25.csv’ saved [50453822/50453822]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M09-xvGPRus1","colab_type":"code","colab":{}},"source":["weather_data = sc.textFile(\"pm25.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nyYKWAlRus3","colab_type":"code","colab":{}},"source":["weather_data_rdd = weather_data.map(lambda line : line.split(\",\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-shIXDJRus6","colab_type":"code","outputId":"544dca1a-b8de-40bd-9f25-ac08a89c7a50","executionInfo":{"status":"ok","timestamp":1577430031395,"user_tz":-480,"elapsed":23776,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["pm25schema = weather_data_rdd.first()\n","print (pm25schema)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['日期', '測站', '測項', '00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ICnDa8u3S8RV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rt1uTvJRus8","colab_type":"code","colab":{}},"source":["import math\n","def remove_row_with_noise (x):\n","    for i in range(3, len(x)):\n","        if not x[i].isdecimal():\n","            return False\n","    return True "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEmVln3vRus-","colab_type":"code","colab":{}},"source":["clean_weather_data = weather_data_rdd\\\n","                    .filter(lambda x: x!=pm25schema)\\\n","                    .filter(remove_row_with_noise)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPO6sPCbRs9L","colab_type":"code","colab":{}},"source":["#print(set(clean_weather_data.map(lambda x : x[1]).collect()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vc9koXVa3AAa","colab_type":"code","colab":{}},"source":["list1 = list(set(clean_weather_data.map(lambda x : x[1]).collect()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lu6Ebd9O33aW","colab_type":"code","colab":{}},"source":["#str1 =''\n","#for i in range(75):\n","#  str2 = \"x[1] == '\" + list1[i] + \"' or \"\n","#  str1 += str2\n","#print(str1[:-3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"28gvryVQ0VZ8","colab":{}},"source":["#len(set(clean_weather_data.map(lambda x : x[1]).collect()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zopn34l3RutA","colab_type":"code","colab":{}},"source":["dalipm25 = clean_weather_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3b1mVdPPKCtP","colab_type":"code","colab":{}},"source":["#dalipm25 = clean_weather_data.filter(lambda x :x[1] == '士林' or x[1] == '埔里' or x[1] == '小港' or x[1] == '觀音' or x[1] == '花蓮' or x[1] == '松山' or x[1] == '新竹' or x[1] == '陽明' or x[1] == '新莊' or x[1] == '安南' or x[1] == '忠明' or x[1] == '屏東' or x[1] == '平鎮' or x[1] == '頭份' or x[1] == '金門' or x[1] == '前金' or x[1] == '中山' or x[1] == '善化' or x[1] == '崙背' or x[1] == '淡水' or x[1] == '林園' or x[1] == '冬山' or x[1] == '馬公' or x[1] == '鳳山' or x[1] == '沙鹿' or x[1] == '潮州' or x[1] == '菜寮' or x[1] == '新營' or x[1] == '新店' or x[1] == '仁武' or x[1] == '臺西' or x[1] == '彰化' or x[1] == '三義' or x[1] == '汐止' or x[1] == '苗栗' or x[1] == '關山' or x[1] == '大里' or x[1] == '湖口' or x[1] == '南投' or x[1] == '馬祖' or x[1] == '宜蘭' or x[1] == '板橋' or x[1] == '美濃' or x[1] == '橋頭' or x[1] == '斗六' or x[1] == '復興' or x[1] == '大寮' or x[1] == '楠梓' or x[1] == '龍潭' or x[1] == '大同' or x[1] == '豐原' or x[1] == '朴子' or x[1] == '嘉義' or x[1] == '麥寮' or x[1] == '桃園' or x[1] == '新港' or x[1] == '左營' or x[1] == '基隆' or x[1] == '土城' or x[1] == '古亭' or x[1] == '中壢' or x[1] == '永和' or x[1] == '萬里' or x[1] == '西屯' or x[1] == '前鎮' or x[1] == '二林' or x[1] == '林口' or x[1] == '臺南' or x[1] == '線西' or x[1] == '臺東' or x[1] == '大園' or x[1] == '三重' or x[1] == '竹東' or x[1] == '恆春' or x[1] == '萬華' )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bg7Rz5vcRutC","colab_type":"code","colab":{}},"source":["from pyspark.sql import SQLContext\n","from pyspark.sql import Row\n","dalipm25row = dalipm25.map(lambda p:\n","        Row(\n","        date = p[0],\n","        location = p[1],\n","        measure = p[2],\n","        hr_01 = float(p[3]),hr_02 = float(p[4]),hr_03 = float(p[5]),hr_04 = float(p[6]),hr_05 = float(p[7]),\n","        hr_06 = float(p[8]),hr_07 = float(p[9]),hr_08 = float(p[10]),hr_09 = float(p[11]),hr_10 = float(p[12]),\n","        hr_11 = float(p[13]),hr_12 = float(p[14]),hr_13 = float(p[15]),hr_14 = float(p[16]),hr_15 = float(p[17]),\n","        hr_16 = float(p[18]),hr_17 = float(p[19]),hr_18 = float(p[20]),hr_19 = float(p[21]),hr_20 = float(p[22]),\n","        hr_21 = float(p[23]),hr_22 = float(p[24]),hr_23 = float(p[25]),hr_24 = float(p[26]),\n","    )\n",")\n","\n","\n","#dalipm25row.take(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLytXM3SVl0u","colab_type":"code","colab":{}},"source":["from pyspark.sql import SQLContext\n","from pyspark.sql import Row\n","from pyspark.sql import SparkSession\n","spark = SparkSession \\\n","    .builder \\\n","    .getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTF_1fjPRutE","colab_type":"code","colab":{}},"source":["df = spark.createDataFrame(dalipm25row)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYCzeJkiRutG","colab_type":"code","colab":{}},"source":["#df.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkf4EjAFa-SO","colab_type":"code","colab":{}},"source":["schemea = [\"date\", \"location\", \"measure\", \n","           \"hr_01\", \"hr_02\", \"hr_03\", \"hr_04\",\n","           \"hr_05\", \"hr_06\", \"hr_07\", \"hr_08\",\n","           \"hr_09\", \"hr_10\", \"hr_11\", \"hr_12\",\n","           \"hr_13\", \"hr_14\", \"hr_15\", \"hr_16\",\n","           \"hr_17\", \"hr_18\", \"hr_19\", \"hr_20\",\n","           \"hr_21\", \"hr_22\", \"hr_23\", \"hr_24\",           \n","          ]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xq6noPy0aGpK","colab_type":"code","colab":{}},"source":["df = dalipm25.toDF(schemea)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxVeXmXVcUQh","colab_type":"code","colab":{}},"source":["#df.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BoQkE1Gob204","colab_type":"code","colab":{}},"source":["for i in df.columns[3:]:\n","  df = df.withColumn(i, df[i].cast(\"float\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbnppctOTlxF","colab_type":"code","colab":{}},"source":["#df.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"od3Ks9FXV7_n","colab_type":"code","colab":{}},"source":["df_pm10 = df.select(\\\n","                    df.date.alias(\"datepm10\"),\\\n","                    df.hr_09.alias(\"hr_09_pm10\"),\\\n","                    df.hr_10.alias(\"hr_10_pm10\"),\\\n","                    df.hr_11.alias(\"hr_11_pm10\"),\\\n","                    df.hr_12.alias(\"hr_12_pm10\"),\\\n","                    \"measure\")\\\n","                    .filter(df.measure==\"PM10\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjH8z-0uWOg8","colab_type":"code","colab":{}},"source":["#df_pm10.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nlNQir4WXWR","colab_type":"code","colab":{}},"source":["df_pm25 = df.select(\\\n","                    df.date.alias(\"datepm25\"),\\\n","                    df.hr_09.alias(\"hr_09_pm25\"),\\\n","                    df.hr_10.alias(\"hr_10_pm25\"),\\\n","                    df.hr_11.alias(\"hr_11_pm25\"),\\\n","                    df.hr_12.alias(\"hr_12_pm25\"),\\\n","                    \"measure\")\\\n","                    .filter(df.measure==\"PM2.5\") \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZT860Q4c9Nq","colab_type":"code","colab":{}},"source":["#df_pm25.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dalCcpYSRutK","colab_type":"code","colab":{}},"source":["traing_data = df_pm25\\\n","    .join(df_pm10, df_pm25.datepm25==df_pm10.datepm10)\\\n","    .drop(\"measure\")\\\n","    .drop(\"datepm10\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Gj0FE_cRutM","colab_type":"code","colab":{}},"source":["#traing_data.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OU7EIZfYRutN","colab_type":"code","colab":{}},"source":["#traing_data.corr(\"hr_09_NO2\", \"hr_09_\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sRvAsVARutP","colab_type":"code","colab":{}},"source":["from pyspark.sql import functions as F\n","formulated_traning_data = traing_data\\\n","            .select(\"*\", F.when(traing_data.hr_12_pm25 > 50, 1).otherwise(0))\\\n","            .drop(\"hr_12_pm10\")\\\n","            .drop(\"hr_12_pm25\")\\\n","            .drop(\"datepm25\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7DuF9LBe3yI","colab_type":"code","colab":{}},"source":["#formulated_traning_data.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BFqdBaURutR","colab_type":"code","colab":{}},"source":["from pyspark.sql import functions as F\n","formulated_traning_data = traing_data\\\n","            .select(\"*\", F.when(traing_data.hr_12_pm25 > 50, 1).otherwise(0))\\\n","            .withColumnRenamed(\"CASE WHEN (hr_12_pm25 > 50) THEN 1 ELSE 0 END\", \"pm25_condiction\")\\\n","            .drop(\"hr_12_pm10\")\\\n","            .drop(\"hr_12_pm25\")\\\n","            .drop(\"datepm25\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URWluTXVRutT","colab_type":"code","colab":{}},"source":["#formulated_traning_data.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"375VQe-3HHd8","colab_type":"text"},"source":["# 預處理Model"]},{"cell_type":"markdown","metadata":{"id":"oWWw3SYPHSUk","colab_type":"text"},"source":["# Decision Tree Model"]},{"cell_type":"code","metadata":{"id":"c1bx_NImHG5l","colab_type":"code","colab":{}},"source":["from pyspark.mllib.regression import LabeledPoint\n","\n","LabelPoints = formulated_traning_data.rdd\\\n","            .map(lambda r: LabeledPoint(r.pm25_condiction, \\\n","                                        [r.hr_09_pm25, r.hr_10_pm25, r.hr_11_pm25, \\\n","                                         r.hr_09_pm10, r.hr_10_pm10, r.hr_11_pm10 ]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZMq84EsHV5N","colab_type":"code","colab":{}},"source":["(trainData,validationData,testData) = LabelPoints.randomSplit([10,0,0]) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRfC-9DiHYFK","colab_type":"code","colab":{}},"source":["from pyspark.mllib.tree import DecisionTree, DecisionTreeModel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NBweH6XHhvz","colab_type":"code","colab":{}},"source":["DTModel = DecisionTree.trainClassifier(trainData,\n","        numClasses=2,\n","        categoricalFeaturesInfo={},\n","        impurity=\"entropy\",\n","        maxDepth=20,\n","        maxBins=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdpsZ1qEHivx","colab_type":"code","colab":{}},"source":["# Save model\n","DTModel.save(sc, \"content/drive/My Drive/colab/model/DTModel\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2O2LkMVH4pS","colab_type":"text"},"source":["# Random Forest Model"]},{"cell_type":"code","metadata":{"id":"mInG7PczH7yF","colab_type":"code","colab":{}},"source":["from pyspark.mllib.tree import RandomForest, RandomForestModel\n","from pyspark.mllib.util import MLUtils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJaxcGkcH9zK","colab_type":"code","colab":{}},"source":["RFModel = RandomForest.trainClassifier(trainData, numClasses=2, categoricalFeaturesInfo={},\n","                                     numTrees=4, featureSubsetStrategy=\"auto\",\n","                                     impurity='entropy', maxDepth=20, maxBins=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Qo7x7dsIPf4","colab_type":"code","colab":{}},"source":["# Save model\n","RFModel.save(sc, \"content/drive/My Drive/colab/model/RFModel\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzjaXmuBIef9","colab_type":"text"},"source":["# Regression"]},{"cell_type":"code","metadata":{"id":"b8CI2PEDIRfD","colab_type":"code","colab":{}},"source":["regression_training = \\\n","             traing_data.drop(\"hr_12_pm10\")\\\n","            .drop(\"datepm25\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UYofeUEIi4n","colab_type":"code","colab":{}},"source":["from pyspark.mllib.regression import LabeledPoint\n","\n","LabelPoints = regression_training.rdd\\\n","            .map(lambda r: LabeledPoint(r.hr_12_pm25, \\\n","                                        [r.hr_09_pm25, r.hr_10_pm25, r.hr_11_pm25, \\\n","                                         r.hr_09_pm10, r.hr_10_pm10, r.hr_11_pm10]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VAMSH_bIlgl","colab_type":"code","colab":{}},"source":["(trainData,validationData,testData) = LabelPoints.randomSplit([10,0,0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlF0d_kVIvKW","colab_type":"code","colab":{}},"source":["from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n","from pyspark.mllib.util import MLUtils\n","\n","\n","REModel = DecisionTree.trainRegressor(trainData, categoricalFeaturesInfo={},\n","                                    impurity='variance', maxDepth=5, maxBins=32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ps-SyQ4tI1FV","colab_type":"code","colab":{}},"source":["# Save model\n","REModel.save(sc, \"content/drive/My Drive/colab/model/REModel\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WIirPqhiUmFs","colab_type":"text"},"source":["# 測資處理"]},{"cell_type":"code","metadata":{"id":"HW_pAQ6n17QC","colab_type":"code","outputId":"ba55c8cb-e836-4438-f034-42de506165c5","executionInfo":{"status":"ok","timestamp":1577430528826,"user_tz":-480,"elapsed":520364,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":463}},"source":["!wget \"https://www.dropbox.com/s/3tejnx4i3v2fv0v/pm%2025%20test%20samples.zip?dl=0\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-12-27 07:10:33--  https://www.dropbox.com/s/3tejnx4i3v2fv0v/pm%2025%20test%20samples.zip?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:601b:1::a27d:801\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/3tejnx4i3v2fv0v/pm%2025%20test%20samples.zip [following]\n","--2019-12-27 07:10:34--  https://www.dropbox.com/s/raw/3tejnx4i3v2fv0v/pm%2025%20test%20samples.zip\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com/cd/0/inline/AvCBDjg2uBD7jtHCZ2sy1y-2WeqAl4gBWto-natPe2As_iFljaQgaJy2iBjMTtS8SA1mcRMxYgs9sAuvHIfTLSr3a2zAkLhzjgeYqD3Y5-oi7HYmRXwV9sGVlM6_pJcX5ls/file# [following]\n","--2019-12-27 07:10:34--  https://uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com/cd/0/inline/AvCBDjg2uBD7jtHCZ2sy1y-2WeqAl4gBWto-natPe2As_iFljaQgaJy2iBjMTtS8SA1mcRMxYgs9sAuvHIfTLSr3a2zAkLhzjgeYqD3Y5-oi7HYmRXwV9sGVlM6_pJcX5ls/file\n","Resolving uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com (uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com)... 162.125.3.6, 2620:100:6018:6::a27d:306\n","Connecting to uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com (uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com)|162.125.3.6|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: /cd/0/inline2/AvAAmTPJy_dO1Jt7zsVVfqbIzwdaejYYR5_fI4qtiWZ2ce3bUnSq76R6eMq26TYH_WIKoB-T9WbeCyKGSMXsgIEtjruOyYezIrSqdPbSu6_IGUWmh0U77EF4KKdyhqbciIh71WVhdv00MLojADdFhFRs-tz2k_fqp0tNTR6GDgsIexKBdo7r4By48TbEJUbh6Wymwu5mfGPd0iOfuI_NKvr-4kKQRuihRiyc0Kqv4RoBvA_gg51HZ2SVdWYfNx-gKob0S-45wAJTKYGbZfpiNV0lTr0C6RFEZ0j7X3KLe3Qg9AHyqGjUReI2adNe-JyviDbOGMHHFzcrfQhKqg9R5VpVsSbmLjPddfH4qiNXnNdUFw/file [following]\n","--2019-12-27 07:10:34--  https://uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com/cd/0/inline2/AvAAmTPJy_dO1Jt7zsVVfqbIzwdaejYYR5_fI4qtiWZ2ce3bUnSq76R6eMq26TYH_WIKoB-T9WbeCyKGSMXsgIEtjruOyYezIrSqdPbSu6_IGUWmh0U77EF4KKdyhqbciIh71WVhdv00MLojADdFhFRs-tz2k_fqp0tNTR6GDgsIexKBdo7r4By48TbEJUbh6Wymwu5mfGPd0iOfuI_NKvr-4kKQRuihRiyc0Kqv4RoBvA_gg51HZ2SVdWYfNx-gKob0S-45wAJTKYGbZfpiNV0lTr0C6RFEZ0j7X3KLe3Qg9AHyqGjUReI2adNe-JyviDbOGMHHFzcrfQhKqg9R5VpVsSbmLjPddfH4qiNXnNdUFw/file\n","Reusing existing connection to uc9df6f1d1d313e275efd35229d3.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 385298 (376K) [application/zip]\n","Saving to: ‘pm 25 test samples.zip?dl=0’\n","\n","pm 25 test samples. 100%[===================>] 376.27K  --.-KB/s    in 0.05s   \n","\n","2019-12-27 07:10:35 (8.05 MB/s) - ‘pm 25 test samples.zip?dl=0’ saved [385298/385298]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oakGAFnu2gLH","colab_type":"code","outputId":"1e1e4616-5265-4da0-9c52-cba334717deb","executionInfo":{"status":"ok","timestamp":1577430530386,"user_tz":-480,"elapsed":521887,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["!unzip 'pm 25 test samples.zip?dl=0'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  pm 25 test samples.zip?dl=0\n","  inflating: 2015_04_01_loc5_PM2.5_23.csv  \n","   creating: __MACOSX/\n","  inflating: __MACOSX/._2015_04_01_loc5_PM2.5_23.csv  \n","  inflating: 2015_11_01_loc1_PM2.5_11.csv  \n","  inflating: __MACOSX/._2015_11_01_loc1_PM2.5_11.csv  \n","  inflating: 2015_05_01_loc4_PM2.5_03.csv  \n","  inflating: __MACOSX/._2015_05_01_loc4_PM2.5_03.csv  \n","  inflating: 2015_05_05_loc3_PM2.5_05.csv  \n","  inflating: __MACOSX/._2015_05_05_loc3_PM2.5_05.csv  \n","  inflating: 2015_07_12_loc2_PM2.5_11.csv  \n","  inflating: __MACOSX/._2015_07_12_loc2_PM2.5_11.csv  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"McYDiAMD3NcK","colab_type":"code","outputId":"d14623be-5ca6-4826-b7b5-63b8aaca3336","executionInfo":{"status":"ok","timestamp":1577430531710,"user_tz":-480,"elapsed":523189,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" 2015_04_01_loc5_PM2.5_23.csv   content      'pm 25 test samples.zip?dl=0'\n"," 2015_05_01_loc4_PM2.5_03.csv   drive\t      sample_data\n"," 2015_05_05_loc3_PM2.5_05.csv   init_env.sh   spark-2.2.0-bin-hadoop2.7.tgz\n"," 2015_07_12_loc2_PM2.5_11.csv   __MACOSX      spark-warehouse\n"," 2015_11_01_loc1_PM2.5_11.csv   pm25.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SVhmIfO6OA7u","colab_type":"code","outputId":"ab82f444-ac7d-42e6-dc07-a48eab4bc7e9","executionInfo":{"status":"ok","timestamp":1577431110795,"user_tz":-480,"elapsed":1685,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls /content/drive/My\\ Drive/colab/pm25_testdata/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["001.csv  002.csv  003.csv  004.csv  005.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4kVNSYRsV3j5","colab_type":"code","colab":{}},"source":["def vote(choose):\n","  if sum(choose)>=2:\n","    ans = 1\n","  else:\n","    ans = 0\n","  return ans"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lA9hhoEUOS9r","colab_type":"code","outputId":"e80d6eed-53c0-4107-eda0-90020ca43bbe","executionInfo":{"status":"ok","timestamp":1577433960396,"user_tz":-480,"elapsed":9746,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from pyspark.mllib.regression import LabeledPoint\n","import time\n","\n","ans = \"[\"\n","total_test = 5\n","\n","for i in range(total_test):\n","  num = i+1\n","  print('Round: ',num)\n","  if num < 10:\n","    file_num = '/content/drive/My Drive/colab/pm25_testdata/00' + str(num) + '.csv'\n","  elif num >= 10 and num < 100:\n","    file_num = '/content/drive/My Drive/colab/pm25_testdata/0' + str(num) + '.csv'\n","  else:\n","    file_num = '/content/drive/My Drive/colab/pm25_testdata/' + str(num) + '.csv'\n","  print(file_num)\n","  # get start time\n","  start = time.time()\n","\n","  # read file\n","  test_data = sc.textFile(file_num)\n","  test_data_rdd = test_data.map(lambda line : line.split(\",\"))\n","  test_data_rdd = test_data_rdd.filter(lambda x: x[2] == 'PM2.5' or x[2] == 'PM10')\n","\n","  # get list\n","  tt_data = test_data_rdd.collect()\n","\n","  ttt_data = tt_data[-1] #pm25 this day\n","  ttt_pm10_data = tt_data[-2] #pm10 this day\n","  ttt_data_yes = tt_data[-3]\n","  ttt_pm10_yes = tt_data[-4]\n","  print(ttt_data)\n","  print(ttt_pm10_data)\n","  print(ttt_data_yes)\n","  print(ttt_pm10_yes)\n","  predict = 1\n","  for i in range(-1,-25,-1):\n","    if ttt_data[i] != '':\n","      predict = (i + 26) % 24 \n","      break\n","  print(predict)\n","\n","  if predict == 1:\n","    ii = 24\n","    only1data = ttt_data[ii:]\n","    onlypm10data = ttt_pm10_data[ii:]\n","    print(only1data)\n","    print(onlypm10data)\n","    only1data.extend(onlypm10data)\n","    only1data_rdd = sc.parallelize(only1data)\n","    only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","    only1data_rdd.take(6)\n","    \n","  if predict == 2:\n","    only1data = ttt_data[3]\n","    onlypm10data = ttt_pm10_data[3]\n","    temp = ttt_data_yes[-2:]\n","    temp.extend(only1data)\n","    only1data = temp\n","    temp = ttt_pm10_yes[-2:]\n","    temp.extend(onlypm10data)\n","    onlypm10data = temp\n","    print(only1data)\n","    print(onlypm10data)\n","    only1data.extend(onlypm10data)\n","    only1data_rdd = sc.parallelize(only1data)\n","    only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","    only1data_rdd.take(6) \n","\n","  if predict == 3:\n","    only1data = ttt_data[3:5]\n","    onlypm10data = ttt_pm10_data[3:5]\n","    temp = ttt_data_yes[-1]\n","    temp.extend(only1data)\n","    only1data = temp\n","    temp = ttt_pm10_yes[-1]\n","    temp.extend(onlypm10data)\n","    onlypm10data = temp\n","    print(only1data)\n","    print(onlypm10data)\n","    only1data.extend(onlypm10data)\n","    only1data_rdd = sc.parallelize(only1data)\n","    only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","    only1data_rdd.take(6) \n","\n","    \n","  if predict > 3 :\n","    ii = predict + 2\n","    only1data = ttt_data[ii-3:ii]\n","    onlypm10data = ttt_pm10_data[ii-3:ii]\n","    print(only1data)\n","    print(onlypm10data)\n","    only1data.extend(onlypm10data)\n","    only1data_rdd = sc.parallelize(only1data)\n","    only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","    only1data_rdd.take(6)\n","\n","  \n","  only1_data = LabeledPoint(1,only1data)\n","  only1_data\n","\n","  # Decision Tree Model\n","  Load_DTModel = DecisionTreeModel.load(sc, \"content/drive/My Drive/colab/model/DTModel\")\n","  prediction_DT = Load_DTModel.predict(only1_data.features)\n","  print('Prediction_DT: ', int(prediction_DT))\n","\n","  # Random Forest Model\n","  Load_RFModel = RandomForestModel.load(sc, \"content/drive/My Drive/colab/model/RFModel\")\n","  prediction_RF = Load_RFModel.predict(only1_data.features)\n","  print('Prediction_RF: ', int(prediction_RF))\n","\n","  # Regression Model\n","  Load_REModel = DecisionTreeModel.load(sc, \"content/drive/My Drive/colab/model/REModel\")\n","  prediction_data = Load_REModel.predict(only1_data.features)\n","  print('Regression Model: ', prediction_data)\n","\n","  # determine while > 50\n","  if(prediction_data>50):\n","    prediction_RE=1\n","  else:\n","    prediction_RE=0\n","  print('Prediction_RE: ', prediction_RE)\n","\n","  choose=[]\n","  choose.append(int(prediction_DT))\n","  choose.append(int(prediction_RF))\n","  choose.append(prediction_RE)\n","  print('Choose result: ', choose)\n","  # vote result\n","  vote_result = vote(choose)\n","  print('Vote result: ', vote(choose))\n","  \n","  # update ans\n","  ans += str(vote_result)\n","  if num != total_test:\n","    ans += \",\"\n","  else:\n","    ans += \"]\"\n","\n","  # \" \"\n","  \"\"\"\n","  ans += \"\\\"\"\n","  ans += str(vote_result)\n","  if num != total_test:\n","    ans += \"\\\",\"\n","  else:\n","    ans += \"\\\"]\"\n","  \"\"\"\n","\n","  # get end time\n","  end = time.time()\n","  print('Period: ' + str(round(end-start,2)) + 's')\n","  print(\"\\n\\n\")\n","\n","print(\"\\n##############################################################################\")\n","print(\"Answer: \",ans)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Round:  1\n","/content/drive/My Drive/colab/pm25_testdata/001.csv\n","['2015/04/01', ' ', 'PM2.5', '34', '35', '36', '26', '25', '31', '26', '28', '28', '26', '23', '24', '37', '34', '31', '20', '27', '20', '19', '14', '16', '16', '18', '24']\n","['2015/04/01', ' ', 'PM10', '88', '99', '99', '86', '86', '88', '81', '64', '61', '60', '71', '82', '81', '82', '69', '72', '67', '64', '61', '60', '60', '62', '61', '60']\n","['2015/03/31', ' ', 'PM2.5', '20', '15', '18', '16', '20', '21', '27', '27', '28', '30', '29', '26', '27', '23', '20', '20', '19', '23', '12', '20', '13', '20', '16', '20']\n","['2015/03/31', ' ', 'PM10', '58', '50', '43', '48', '45', '53', '54', '66', '68', '67', '63', '61', '60', '60', '58', '69', '73', '72', '58', '56', '59', '63', '63', '67']\n","1\n","['16', '18', '24']\n","['62', '61', '60']\n","Prediction_DT:  0\n","Prediction_RF:  0\n","Regression Model:  23.406565319396496\n","Prediction_RE:  0\n","Choose result:  [0, 0, 0]\n","Vote result:  0\n","Period: 1.66s\n","\n","\n","\n","Round:  2\n","/content/drive/My Drive/colab/pm25_testdata/002.csv\n","['2015/05/01', '', 'PM2.5', '44', '51', '49', '55', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n","['2015/05/01', '', 'PM10', '82', '79', '88', '84', '78', '79', '93', '114', '128', '128', '116', '98', '87', '82', '73', '65', '68', '74', '71', '71', '77', '87', '85', '76']\n","['2015/04/30', '', 'PM2.5', '33', '37', '36', '34', '29', '33', '43', '47', '55', '47', '43', '41', '49', '48', '40', '37', '41', '39', '33', '43', '46', '55', '45', '51']\n","['2015/04/30', '', 'PM10', '65', '69', '79', '79', '75', '72', '74', '85', '86', '86', '78', '83', '85', '89', '82', '74', '69', '63', '67', '63', '78', '86', '96', '83']\n","5\n","['51', '49', '55']\n","['79', '88', '84']\n","Prediction_DT:  1\n","Prediction_RF:  1\n","Regression Model:  53.60826319816373\n","Prediction_RE:  1\n","Choose result:  [1, 1, 1]\n","Vote result:  1\n","Period: 2.09s\n","\n","\n","\n","Round:  3\n","/content/drive/My Drive/colab/pm25_testdata/003.csv\n","['2015/05/05', '', 'PM2.5', '21', '19', '21', '28', '31', '33', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n","['2015/05/05', '', 'PM10', '51', '42', '40', '45', '49', '51', '49', '46', '45', '40', '38', '38', '38', '37', '33', '', '42', '53', '56', '46', '46', '51', '49', '50']\n","['2015/05/04', '', 'PM2.5', '8', '10', '12', '6', '9', '11', '11', '15', '17', '12', '10', '11', '11', '16', '20', '18', '17', '25', '20', '18', '22', '24', '25', '24']\n","['2015/05/04', '', 'PM10', '32', '35', '33', '29', '26', '27', '27', '29', '33', '29', '29', '28', '33', '39', '43', '40', '35', '44', '43', '38', '45', '55', '57', '55']\n","7\n","['28', '31', '33']\n","['45', '49', '51']\n","Prediction_DT:  0\n","Prediction_RF:  0\n","Regression Model:  32.07853462431346\n","Prediction_RE:  0\n","Choose result:  [0, 0, 0]\n","Vote result:  0\n","Period: 1.75s\n","\n","\n","\n","Round:  4\n","/content/drive/My Drive/colab/pm25_testdata/004.csv\n","['2015/07/12', '', 'PM2.5', '13', '15', '11', '13', '18', '22', '27', '22', '22', '20', '19', '13', '', '', '', '', '', '', '', '', '', '', '', '']\n","['2015/07/12', '', 'PM10', '25', '20', '19', '22', '28', '33', '36', '34', '35', '41', '33', '31', '21', '32', '25', '25', '26', '32', '40', '37', '40', '36', '43', '38']\n","['2015/07/11', '', 'PM2.5', '5', '9', '5', '5', '4', '8', '7', '9', '5', '5', '3', '6', '4', '12', '12', '21', '18', '24', '20', '19', '11', '13', '12', '14']\n","['2015/07/11', '', 'PM10', '31', '26', '24', '22', '24', '27', '24', '32', '26', '45', '36', '43', '22', '33', '26', '31', '30', '34', '35', '30', '27', '25', '29', '28']\n","13\n","['20', '19', '13']\n","['41', '33', '31']\n","Prediction_DT:  0\n","Prediction_RF:  0\n","Regression Model:  14.050414302149717\n","Prediction_RE:  0\n","Choose result:  [0, 0, 0]\n","Vote result:  0\n","Period: 1.84s\n","\n","\n","\n","Round:  5\n","/content/drive/My Drive/colab/pm25_testdata/005.csv\n","['2015/11/01', '', 'PM2.5', '42', '39', '40', '39', '39', '38', '37', '42', '46*', '42', '39', '39', '', '', '', '', '', '', '', '', '', '', '', '']\n","['2015/11/01', '', 'PM10', '50', '46', '44', '44', '48', '49', '51', '50', '44', '46', '51', '45', '31', '21', '16', '17', '18', '18', '26', '31', '28', '28', '32', '32']\n","['2015/10/31', '', 'PM2.5', '44', '38', '33', '33', '34', '32', '31', '31', '34', '33', '35', '44', '44', '34', '30', '34', '42', '44', '35', '33', '37', '34', '37', '42']\n","['2015/10/31', '', 'PM10', '53', '46', '51', '51', '48', '44', '44', '44', '42', '39', '42', '49', '50', '43', '39', '46', '54', '57', '54', '54', '56', '57', '56', '51']\n","13\n","['42', '39', '39']\n","['46', '51', '45']\n","Prediction_DT:  0\n","Prediction_RF:  0\n","Regression Model:  35.30752906222736\n","Prediction_RE:  0\n","Choose result:  [0, 0, 0]\n","Vote result:  0\n","Period: 1.82s\n","\n","\n","\n","\n","##############################################################################\n","Answer:  [0,1,0,0,0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3GG5assMipud","colab_type":"code","colab":{}},"source":["import time\n","start = time.time()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFOZnRYIUpu9","colab_type":"code","colab":{}},"source":["test_data = sc.textFile(\"./2015_05_05_loc3_PM2.5_05.csv\")\n","#/content/drive/My Drive/colab/2015_04_01_loc5_PM2.5_23.csv\n","test_data_rdd = test_data.map(lambda line : line.split(\",\"))\n","test_data_rdd = test_data_rdd.filter(lambda x: x[2] == 'PM2.5' or x[2] == 'PM10')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJU0g5naWJd7","colab_type":"code","outputId":"9efc75ed-5e5a-45c3-806d-c2dbf8a6e303","executionInfo":{"status":"ok","timestamp":1577431028613,"user_tz":-480,"elapsed":1720,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["tt_data = test_data_rdd.collect()\n","\n","ttt_data = tt_data[-1] #pm25 this day\n","ttt_pm10_data = tt_data[-2] #pm10 this day\n","ttt_data_yes = tt_data[-3]\n","ttt_pm10_yes = tt_data[-4]\n","print(ttt_data)\n","print(ttt_pm10_data)\n","print(ttt_data_yes)\n","print(ttt_pm10_yes)\n","predict = 1\n","for i in range(-1,-25,-1):\n","  if ttt_data[i] != '':\n","    predict = (i + 26) % 24 \n","    break\n","print(predict)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['2015/05/05', '', 'PM2.5', '21', '19', '21', '28', '31', '33', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n","['2015/05/05', '', 'PM10', '51', '42', '40', '45', '49', '51', '49', '46', '45', '40', '38', '38', '38', '37', '33', '', '42', '53', '56', '46', '46', '51', '49', '50']\n","['2015/05/04', '', 'PM2.5', '8', '10', '12', '6', '9', '11', '11', '15', '17', '12', '10', '11', '11', '16', '20', '18', '17', '25', '20', '18', '22', '24', '25', '24']\n","['2015/05/04', '', 'PM10', '32', '35', '33', '29', '26', '27', '27', '29', '33', '29', '29', '28', '33', '39', '43', '40', '35', '44', '43', '38', '45', '55', '57', '55']\n","7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VVwD222CKUML","colab_type":"code","outputId":"8c9cde0d-322c-4c72-80e8-45891aa33f84","executionInfo":{"status":"ok","timestamp":1577431028852,"user_tz":-480,"elapsed":1933,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["if predict == 1:\n","  ii = 24\n","  only1data = ttt_data[ii:]\n","  onlypm10data = ttt_pm10_data[ii:]\n","  print(only1data)\n","  print(onlypm10data)\n","  only1data.extend(onlypm10data)\n","  only1data_rdd = sc.parallelize(only1data)\n","  only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","  only1data_rdd.take(6)\n","  \n","if predict == 2:\n","  only1data = ttt_data[3]\n","  onlypm10data = ttt_pm10_data[3]\n","  temp = ttt_data_yes[-2:]\n","  temp.extend(only1data)\n","  only1data = temp\n","  temp = ttt_pm10_yes[-2:]\n","  temp.extend(onlypm10data)\n","  onlypm10data = temp\n","  print(only1data)\n","  print(onlypm10data)\n","  only1data.extend(onlypm10data)\n","  only1data_rdd = sc.parallelize(only1data)\n","  only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","  only1data_rdd.take(6) \n","\n","if predict == 3:\n","  only1data = ttt_data[3:5]\n","  onlypm10data = ttt_pm10_data[3:5]\n","  temp = ttt_data_yes[-1]\n","  temp.extend(only1data)\n","  only1data = temp\n","  temp = ttt_pm10_yes[-1]\n","  temp.extend(onlypm10data)\n","  onlypm10data = temp\n","  print(only1data)\n","  print(onlypm10data)\n","  only1data.extend(onlypm10data)\n","  only1data_rdd = sc.parallelize(only1data)\n","  only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","  only1data_rdd.take(6) \n","\n","  \n","if predict > 3 :\n","  ii = predict + 2\n","  only1data = ttt_data[ii-3:ii]\n","  onlypm10data = ttt_pm10_data[ii-3:ii]\n","  print(only1data)\n","  print(onlypm10data)\n","  only1data.extend(onlypm10data)\n","  only1data_rdd = sc.parallelize(only1data)\n","  only1data_rdd = only1data_rdd.map(lambda x: float(x))\n","  only1data_rdd.take(6)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['28', '31', '33']\n","['45', '49', '51']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"85nBKmGYd-_r","colab_type":"code","colab":{}},"source":["from pyspark.mllib.regression import LabeledPoint\n","\n","only1_data = LabeledPoint(1,only1data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xVCdO13eLC2","colab_type":"code","outputId":"9935983f-ce38-4771-ee23-9d9af8a19e75","executionInfo":{"status":"ok","timestamp":1577431028856,"user_tz":-480,"elapsed":1820,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["only1_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LabeledPoint(1.0, [28.0,31.0,33.0,45.0,49.0,51.0])"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"markdown","metadata":{"id":"LCe7YiHBi4kM","colab_type":"text"},"source":["# Mlib API\n"]},{"cell_type":"markdown","metadata":{"id":"jjKJyUQtmVt_","colab_type":"text"},"source":["## Decision Tree Model"]},{"cell_type":"code","metadata":{"id":"tbOhu90M1oFJ","colab_type":"code","colab":{}},"source":["# load model\n","Load_DTModel = DecisionTreeModel.load(sc, \"content/drive/My Drive/colab/model/DTModel\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjDzrHiuRutb","colab_type":"code","colab":{}},"source":["prediction_DT = Load_DTModel.predict(only1_data.features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESggc4uZkRJn","colab_type":"code","outputId":"a19a859b-af12-4e6e-bb43-a95d8f1ae9d9","executionInfo":{"status":"ok","timestamp":1577431029753,"user_tz":-480,"elapsed":2525,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(int(prediction_DT))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1EKbxjsSulaP","colab_type":"code","outputId":"505b81f7-58f5-405d-f0e0-4c48f05b394d","executionInfo":{"status":"ok","timestamp":1577431032051,"user_tz":-480,"elapsed":4764,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["!ls /content/drive/My\\ Drive/colab/\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["13_Question.json\t      dict.txt.big\t      Questions_with_Ans.json\n","2015_04_01_loc5_PM2.5_23.csv  Inverted_index.csv      titanic\n","bkai00mp.ttf\t\t      jsonJieba-tran.json     title.json\n","dictionary.csv\t\t      model\t\t      userdict_oldd.txt\n","dictionary__.json\t      pm2.5Taiwan.csv\t      userdict_old.txt\n","dictionary.json\t\t      pm25_testdata\t      userdict.txt\n","dictionary_noun_id.csv\t      Questions_200.json      Wordcount.csv\n","dictt.txt.big\t\t      questions_example.json\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tma2D9sJmPLW","colab_type":"text"},"source":["## Random Forrest Model"]},{"cell_type":"code","metadata":{"id":"F20xp65Urxti","colab_type":"code","colab":{}},"source":["# load model\n","Load_RFModel = RandomForestModel.load(sc, \"content/drive/My Drive/colab/model/RFModel\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZh8jA0FPshC","colab_type":"code","colab":{}},"source":["prediction_RF = Load_RFModel.predict(only1_data.features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGusI3VnQ-o7","colab_type":"code","outputId":"cfbccd1a-8434-4cba-8148-392cadd3e41a","executionInfo":{"status":"ok","timestamp":1577431032748,"user_tz":-480,"elapsed":5354,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(int(prediction_RF))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NH4f0EaZyMzn","colab_type":"text"},"source":["# Regression"]},{"cell_type":"code","metadata":{"id":"trP4YuEZJKfB","colab_type":"code","colab":{}},"source":["# load model\n","Load_REModel = DecisionTreeModel.load(sc, \"content/drive/My Drive/colab/model/REModel\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jZpLkO4KR65Y","colab_type":"code","colab":{}},"source":["prediction_data = Load_REModel.predict(only1_data.features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FcnVyX8kSBS5","colab_type":"code","outputId":"2d8e592a-3a58-46b4-8492-ac204da99102","executionInfo":{"status":"ok","timestamp":1577431033019,"user_tz":-480,"elapsed":5570,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(prediction_data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["32.07853462431346\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9TQ5UwsFaNTH","colab_type":"code","outputId":"bec2116c-b549-4303-adc3-7ad6efeee0ca","executionInfo":{"status":"ok","timestamp":1577431033020,"user_tz":-480,"elapsed":5536,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if(prediction_data>50):\n","  prediction_RE=1\n","else:\n","  prediction_RE=0\n","\n","print(prediction_RE)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uLZSV6hrbI9c","colab_type":"text"},"source":["# Answer"]},{"cell_type":"code","metadata":{"id":"MD3TrqyMbIMd","colab_type":"code","outputId":"240f6c7a-15d6-44ba-a46f-5bfebfe9f6da","executionInfo":{"status":"ok","timestamp":1577431033020,"user_tz":-480,"elapsed":5508,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["choose=[]\n","choose.append(int(prediction_DT))\n","choose.append(int(prediction_RF))\n","choose.append(prediction_RE)\n","print(choose)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JV_z42EognQk","colab_type":"code","outputId":"9ba98fd0-ce31-4892-8feb-e69d55be11bd","executionInfo":{"status":"ok","timestamp":1577431033021,"user_tz":-480,"elapsed":5483,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def vote(choose):\n","  if sum(choose)>=2:\n","    ans = 1\n","  else:\n","    ans = 0\n","  return ans\n","\n","print(vote(choose))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TMUbmX6_iuj2","colab_type":"code","outputId":"5abc0c87-851c-42a4-d93f-e70721ae3fa4","executionInfo":{"status":"ok","timestamp":1577431033025,"user_tz":-480,"elapsed":5464,"user":{"displayName":"吳韋成","photoUrl":"","userId":"04906925710104432369"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["end = time.time()\n","print('Period: ' + str(round(end-start,2)) + 's')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Period: 5.81s\n"],"name":"stdout"}]}]}